import keras
import tensorflow as tf
import common.constants as const
import time
from statistics import mean

data = [
    [0.6913126707077026,0.3909188508987427,0.26155251264572144,0.5843986868858337,0.09481817483901978,0.6329864263534546,0.2306915819644928,0.47205230593681335,0.043422967195510864,0.4889701008796692,0.2571258544921875,0.3859054148197174,0.09031054377555847,0.38396304845809937,0.3028206527233124,0.3234744071960449,0.1677563488483429,0.3105279207229614],
    [0.6954916715621948,0.3857414126396179,0.30983370542526245,0.588404655456543,0.17773430049419403,0.6069890856742859,0.25963062047958374,0.5028026700019836,0.11109453439712524,0.516061544418335,0.26738691329956055,0.40219348669052124,0.12655150890350342,0.3992576599121094,0.3134416341781616,0.3074839115142822,0.2116539478302002,0.3012472987174988],
    [0.6533771753311157,0.3412359654903412,0.31355857849121094,0.46357712149620056,0.1996355801820755,0.49718213081359863,0.2836858332157135,0.3567005693912506,0.14895665645599365,0.3629862666130066,0.3803756833076477,0.2988342046737671,0.45846065878868103,0.3214431703090668,0.4197934865951538,0.2469213604927063,0.48643407225608826,0.2718609571456909],
    [0.6859843134880066,0.544954776763916,0.3108401894569397,0.697772741317749,0.170503169298172,0.7393933534622192,0.2817564010620117,0.5763773322105408,0.11669746041297913,0.572256863117218,0.38404086232185364,0.5211244821548462,0.46110275387763977,0.5524437427520752,0.4213563799858093,0.47314730286598206,0.4915100634098053,0.4914400577545166],
    [0.6894742846488953,0.5839641094207764,0.31661081314086914,0.5731921792030334,0.4027763903141022,0.5558900237083435,0.3258351981639862,0.5129247903823853,0.4149308502674103,0.5158793330192566,0.3541034162044525,0.454237163066864,0.4371050000190735,0.4790622591972351,0.3903990089893341,0.4078759253025055,0.46399128437042236,0.4425944983959198]
]

'''
DNNC

'''
feature_columns = []
for label in const.LABELS:
    feature_columns.append(tf.feature_column.numeric_column(key=label))


def input_fn(features, batch_size=1):
    predict = {}
    for i, label in enumerate(feature_columns):
        predict[label] = [float(features[i])]

    return tf.data.Dataset.from_tensor_slices(predict).batch(batch_size)


def dnnc_predict(landmarks):
    predictions = dnn_classifier.predict(lambda: input_fn(landmarks))    
    for pred_dict in predictions:        
        return pred_dict['class_ids'][0] 


dnn_classifier =  tf.estimator.DNNClassifier(
    feature_columns= feature_columns,
    hidden_units=[32, 10],
    n_classes=3,
    optimizer='Adam',
    model_dir='model\\1653892692\\saved_model'
)


'''
KERAS 
'''
keras_model = keras.models.load_model("model\\gesture_classifier.h5")


'''
COMPROBACION
'''
tiempos = []
for landmarks in data:
    s = time.time()

    dnnc_predict(landmarks)
    # keras_model.predict([landmarks])
    
    e = time.time()
    tiempos.append(e-s)

print(f'\nMedia 5 predicciones (): {mean(tiempos):.3f}s avg')


print("\n"*10)